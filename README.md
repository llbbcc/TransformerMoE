# TransformerMoE
An pytorch implementation of MoE version of "Attention is all you need".
